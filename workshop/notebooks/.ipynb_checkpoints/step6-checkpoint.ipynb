{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Install pip packages required for query workflows.\n",
    "!pip install -q matplotlib\n",
    "!pip install -q ml_metadata\n",
    "\n",
    "# Imports.\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import tensorflow_model_analysis as tfma  # requires numpy 1.15.4.\n",
    "from IPython.display import display, display_html\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "import tensorflow_data_validation as tfdv\n",
    "\n",
    "# Constants for TFX Artifact types.\n",
    "TFX_ARTIFACT_EXAMPLES = 'ExamplesPath'\n",
    "TFX_ARTIFACT_SCHEMA = 'SchemaPath'\n",
    "TFX_ARTIFACT_EXAMPLE_STATS = 'ExampleStatisticsPath'\n",
    "TFX_ARTIFACT_EXAMPLE_VALIDATION = 'ExampleValidationPath'\n",
    "TFX_ARTIFACT_TRANSFORMED_EXAMPLES = 'TransformPath'\n",
    "TFX_ARTIFACT_MODEL = 'ModelExportPath'\n",
    "TFX_ARTIFACT_MODEL_EVAL = 'ModelEvalPath'\n",
    "\n",
    "# Constants for TFX Execution types.\n",
    "TFX_EXECUTION_EXAMPLE_GEN = 'examples_gen'\n",
    "TFX_EXECUTION_STATISTICS_GEN = 'statistics_gen'\n",
    "TFX_EXECUTION_SCHEMA_GEN = 'schema_gen'\n",
    "TFX_EXECUTION_EXAMPLE_VALIDATION = 'example_validation'\n",
    "TFX_EXECUTION_TRANSFORM = 'transform'\n",
    "TFX_EXECUTION_TRAINER = 'trainer'\n",
    "TFX_EXECUTION_EVALUATOR = 'evaluator'\n",
    "\n",
    "def _make_default_sqlite_uri():\n",
    "    return '/'.join([\n",
    "        os.environ['HOME'],\n",
    "        \"airflow/data/tfx_example/pipelines/tfx_example_pipeline_DAG/metadata.db\",\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_metadata_store(\n",
    "    filename_uri='',\n",
    "    connection_mode=metadata_store_pb2.SqliteMetadataSourceConfig.UNKNOWN,\n",
    "    reset=False):    \n",
    "    \"\"\"Returns a metadata_store.MetadataStore handle to a SQLITE backend.\"\"\"\n",
    "    c = metadata_store_pb2.ConnectionConfig()\n",
    "    c.sqlite.filename_uri = filename_uri or _make_default_sqlite_uri()\n",
    "    c.sqlite.connection_mode = connection_mode\n",
    "    return metadata_store.MetadataStore(c)\n",
    "\n",
    "\n",
    "def delete_sqlite_db(filename_uri=''):\n",
    "    os.remove(filename_uri or _make_default_sqlite_uri())\n",
    "\n",
    "\n",
    "def update_airflow_db_airtifacts_uri(extracted_dir=''):\n",
    "    \"\"\"extracted_dir is the location where the airflow data dir is extracted\n",
    "       e.g., /usr/local/google/home/huimiao/airflow/\n",
    "                data/\n",
    "                   taxi_data/\n",
    "                   tfx/\n",
    "       then extracted_dir = '/usr/local/google/home/huimiao/airflow/'\n",
    "    \"\"\"    \n",
    "    store = get_metadata_store(\n",
    "        filename_uri = extracted_dir + \"data/tfx_example/pipelines/tfx_example_pipeline_DAG/metadata.db\",\n",
    "        connection_mode=metadata_store_pb2.SqliteMetadataSourceConfig.READWRITE)\n",
    "    for artifact in store.get_artifacts():\n",
    "        tokens = artifact.uri.split(\"airflow\")\n",
    "        if len(tokens) > 1:\n",
    "            new_uri = extracted_dir + tokens[1]\n",
    "            artifact.uri = new_uri\n",
    "            store.put_artifacts([artifact])\n",
    "\n",
    "            \n",
    "# Utils to display artifacts, executions.\n",
    "def _get_value_str(p):\n",
    "    \"\"\"Returns a string representation of a metadata_store_pb2.Value object.\"\"\"\n",
    "    if p.int_value:\n",
    "        return str(p.int_value)\n",
    "    if p.string_value:\n",
    "        return p.string_value\n",
    "    if p.double_value:\n",
    "        return str(p.double_value)\n",
    "    return ''\n",
    "\n",
    "\n",
    "def get_df_from_artifacts_or_executions(objects, is_artifact):\n",
    "    \"\"\"Returns a `pd.DataFrame` of given artifact/execution objects.\"\"\"\n",
    "    data = {}\n",
    "    for o in objects:\n",
    "        col_map = {}\n",
    "        if is_artifact:\n",
    "            col_map['URI'] = o.uri\n",
    "        for p in o.properties:\n",
    "            col_map[p.upper()] = _get_value_str(o.properties[p])\n",
    "        for p in o.custom_properties:\n",
    "            col_map[p.upper()] = _get_value_str(o.custom_properties[p])\n",
    "        data[o.id] = col_map\n",
    "    df = pd.DataFrame.from_dict(data=data, orient='index').fillna('-')\n",
    "    df.index.name = 'ID'\n",
    "    return df\n",
    "\n",
    "\n",
    "def _get_df_from_single_artifact_or_execution(obj, is_artifact):\n",
    "    \"\"\"Returns a `pd.DataFrame` based on properties of an artifact/execution `obj`.\"\"\"\n",
    "    data = {}\n",
    "    if is_artifact:\n",
    "        data['URI'] = obj.uri\n",
    "    for p in obj.properties:\n",
    "        data[p.upper()] = _get_value_str(obj.properties[p])\n",
    "    for p in obj.custom_properties:\n",
    "        data[p.upper()] = _get_value_str(obj.custom_properties[p])\n",
    "    return pd.DataFrame.from_dict(data=data, orient='index', columns=['']).fillna('-')\n",
    "\n",
    "\n",
    "def get_artifact_df(artifact_id):\n",
    "    \"\"\"Returns a `pd.DataFrame` for artifact with `artifact_id`.\"\"\"\n",
    "    [artifact] = store.get_artifacts_by_id([artifact_id])\n",
    "    return _get_df_from_single_artifact_or_execution(artifact, True)\n",
    "\n",
    "\n",
    "def get_execution_df(execution_id):\n",
    "    \"\"\"Returns a `pd.DataFrame` for execution with `execution_id`.\"\"\"\n",
    "    [execution] = store.get_executions_by_id([execution_id])\n",
    "    return _get_df_from_single_artifact_or_execution(execution, False)\n",
    "\n",
    "\n",
    "def get_artifacts_of_type_df(type_name):\n",
    "    \"\"\"Returns a `pd.DataFrame` of all artifacts with `type`.\"\"\"\n",
    "    return get_df_from_artifacts_or_executions(\n",
    "        store.get_artifacts_by_type(type_name), is_artifact=True)\n",
    "\n",
    "\n",
    "def get_executions_of_type_df(type_name):\n",
    "    \"\"\"Returns a `pd.DataFrame` of all executions with `type`.\"\"\"\n",
    "    return get_df_from_artifacts_or_executions(\n",
    "        store.get_executions_by_type(type_name), is_artifact=False)\n",
    "\n",
    "# Specialized util methods to query lineage for models.\n",
    "\n",
    "def get_trainer_run_id_for_model(model_id):\n",
    "    \"\"\"Returns an execution of type TFX_EXECUTION_TRAINER that generated `model_id`.\"\"\"\n",
    "    trainer_run_ids = []\n",
    "    events = store.get_events_by_artifact_ids([model_id])\n",
    "    for event in events:\n",
    "        if event.type != metadata_store_pb2.Event.DECLARED_OUTPUT:\n",
    "            continue\n",
    "        [execution] = store.get_executions_by_id([event.execution_id])\n",
    "        [execution_type] = store.get_execution_types_by_id([execution.type_id])\n",
    "        if execution_type.name != TFX_EXECUTION_TRAINER:\n",
    "            continue\n",
    "        trainer_run_ids.append(execution.id)\n",
    "    if len(trainer_run_ids) > 1:\n",
    "        raise ValueError('Multiple trainer runs {} generated model artifact {}'.format(\n",
    "            ','.join(trainer_run_ids), model_id))\n",
    "    return trainer_run_ids[0] if trainer_run_ids else None\n",
    "\n",
    "\n",
    "def get_tfma_eval_result_for_model(model_id):\n",
    "    \"\"\"Returns an artifact of type TFX_ARTIFACT_MODEL_EVAL for given `model_id`.\"\"\"\n",
    "    # Get a tfma run for given model_id.\n",
    "    events = store.get_events_by_artifact_ids([model_id])\n",
    "    tfma_run_ids = []\n",
    "    for event in events:\n",
    "        if event.type != metadata_store_pb2.Event.DECLARED_INPUT:\n",
    "            continue\n",
    "        [execution] = store.get_executions_by_id([event.execution_id])\n",
    "        [execution_type] = store.get_execution_types_by_id([execution.type_id])\n",
    "        if execution_type.name != TFX_EXECUTION_EVALUATOR:\n",
    "            continue\n",
    "        tfma_run_ids.append(execution.id)\n",
    "    if not tfma_run_ids:\n",
    "        return None\n",
    "    tfma_run_id = tfma_run_ids[0]\n",
    "\n",
    "    # Get the tfma eval result for the tfma_run_id.\n",
    "    events = store.get_events_by_execution_ids([tfma_run_id])\n",
    "    tfma_eval_results = []\n",
    "    for event in events:\n",
    "        if event.type != metadata_store_pb2.Event.DECLARED_OUTPUT:\n",
    "            continue\n",
    "        [artifact] = store.get_artifacts_by_id([event.artifact_id])\n",
    "        [artifact_type] = store.get_artifact_types_by_id([artifact.type_id])\n",
    "        if artifact_type.name != TFX_ARTIFACT_MODEL_EVAL:\n",
    "            continue\n",
    "        tfma_eval_results.append(artifact)\n",
    "    if len(tfma_eval_results) > 1:\n",
    "        raise ValueError('Multiple tfma eval results {} for tfma run {} of model {}'.format(\n",
    "            ','.join([r.id for r in tfma_eval_results]), tfma_run_id, model_id))\n",
    "    return tfma_eval_results[0] if tfma_eval_results else None\n",
    "\n",
    "# Internal utils used to compute lineage DAG.\n",
    "\n",
    "def _find_upstream_executions(artifact_id):\n",
    "    \"\"\"Returns a list of upstream execution ids.\"\"\"\n",
    "    result = []\n",
    "    for e in store.get_events_by_artifact_ids([artifact_id]):\n",
    "        if e.type in [metadata_store_pb2.Event.DECLARED_OUTPUT, metadata_store_pb2.Event.OUTPUT]:\n",
    "            result.append(e.execution_id)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _find_upstream_artifacts(execution_id):\n",
    "    \"\"\"Returns a list of upstream artifact ids.\"\"\"\n",
    "    result = []\n",
    "    for e in store.get_events_by_execution_ids([execution_id]):\n",
    "        if e.type in [metadata_store_pb2.Event.DECLARED_INPUT, metadata_store_pb2.Event.INPUT]:\n",
    "            result.append(e.artifact_id)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _add_node_attribute(g, node_id, depth, is_artifact):\n",
    "    # if it is not an artifact, use negative gnode id\n",
    "    gnode_id = node_id if is_artifact else -1 * node_id\n",
    "    g.add_node(gnode_id, depth=depth, is_artifact=is_artifact)\n",
    "    node_label = str(node_id) + \"\\n\"\n",
    "    if is_artifact:\n",
    "        [a] = store.get_artifacts_by_id([node_id])\n",
    "        [t] = store.get_artifact_types_by_id([a.type_id])\n",
    "        node_label += t.name\n",
    "    else:\n",
    "        [e] = store.get_executions_by_id([node_id])\n",
    "        [t] = store.get_execution_types_by_id([e.type_id])\n",
    "        node_label += t.name\n",
    "    g.nodes[gnode_id]['_label_'] = node_label\n",
    "\n",
    "    \n",
    "def _add_parents(g, node_id, is_artifact, depth, max_depth=None):\n",
    "    _add_node_attribute(g, node_id, depth, is_artifact)\n",
    "    gnode_id = node_id if is_artifact else -1 * node_id\n",
    "    if gnode_id in g and len(g.in_edges(gnode_id)) > 0: \n",
    "        return\n",
    "    if max_depth is not None and depth > max_depth:\n",
    "        return\n",
    "    if is_artifact:\n",
    "        for e_id in _find_upstream_executions(node_id):\n",
    "            g.add_edge(e_id * -1, node_id)\n",
    "            _add_parents(g, e_id, not is_artifact, depth + 1, max_depth)\n",
    "    else:\n",
    "        for a_id in _find_upstream_artifacts(node_id):\n",
    "            g.add_edge(a_id, node_id * -1)\n",
    "            _add_parents(g, a_id, not is_artifact, depth + 1, max_depth)\n",
    "    \n",
    "\n",
    "def _construct_artifact_lineage(artifact_id, max_depth=None):\n",
    "    \"\"\"Returns a networkx DiGraph representing the lineage of the given artifact_id.\"\"\"\n",
    "    g = nx.DiGraph(query_artifact_id=artifact_id)\n",
    "    if max_depth is None or max_depth > 0:\n",
    "        _add_parents(g, artifact_id, True, 1, max_depth)\n",
    "    return g\n",
    "\n",
    "\n",
    "# Generic utils to get and plot artifact lineage.\n",
    "\n",
    "def get_artifact_lineage(artifact_id, max_depth=None):\n",
    "    \"\"\"Returns lineage of artifact_id as a DAG.\n",
    "       DAG is a networkx DiGraph\n",
    "    \"\"\"\n",
    "    return _construct_artifact_lineage(artifact_id, max_depth)\n",
    "\n",
    "\n",
    "def plot_artifact_lineage(dag):\n",
    "    \"\"\"Use networkx and matplotlib to plot the graph.\n",
    "       The nodes are places from left to right w.r.t. its depth.\n",
    "       Nodes at the same depths are placed vertically.\n",
    "       Artifact is shown in green, and Execution is shown in red.\n",
    "       Nodes are positioned in a bipartite graph layout. \n",
    "    \"\"\"\n",
    "    node_color = \"\"\n",
    "    node_labels = {}\n",
    "    for node_id in dag.nodes:\n",
    "        node_color += 'c' if dag.node[node_id]['is_artifact'] else 'r'\n",
    "        node_labels[node_id] = dag.node[node_id]['_label_']\n",
    "    \n",
    "    pos = {}\n",
    "    a_nodes = []; e_nodes = []\n",
    "    for node_id in dag.nodes:\n",
    "        if node_id > 0:\n",
    "            a_nodes.append(node_id)\n",
    "        else:\n",
    "            e_nodes.append(node_id)\n",
    "\n",
    "    def order_nodes_by_depth(node_id):\n",
    "        return -1 * dag.node[node_id]['depth']\n",
    "            \n",
    "    a_nodes.sort(key = order_nodes_by_depth)\n",
    "    e_nodes.sort(key = order_nodes_by_depth) \n",
    "    a_node_y = 0\n",
    "    e_node_y = 0.2\n",
    "    a_offset = -0.5 if len(a_nodes) % 2 == 0 else 0\n",
    "    e_offset = -0.5 if len(e_nodes) % 2 == 0 else 0\n",
    "    a_node_x_min = -1 * len(a_nodes)/2 + a_offset\n",
    "    e_node_x_min = -1 * len(e_nodes)/2 + e_offset\n",
    "    for a_id in a_nodes:\n",
    "        pos[a_id] = [a_node_x_min, a_node_y]\n",
    "        a_node_x_min += 1\n",
    "    for e_id in e_nodes:\n",
    "        pos[e_id] = [e_node_x_min, e_node_y]\n",
    "        e_node_x_min += 1    \n",
    "\n",
    "    nx.draw(dag, pos=pos, \n",
    "            node_size=3000, node_color=node_color, labels=node_labels, node_shape = '8')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def get_and_plot_artifact_lineage(artifact_id, max_depth=None):\n",
    "    plot_artifact_lineage(get_artifact_lineage(artifact_id, max_depth=max_depth))\n",
    "\n",
    "\n",
    "def display_data_stats_for_model(model_id, other_model_id=None):\n",
    "    \"\"\"Visualizes stats for data that generated `model_id` and optionally `other_model_id`.\"\"\"\n",
    "    lhs_statistics = tfdv.load_statistics(\n",
    "            get_input_artifact(model_id, TFX_ARTIFACT_EXAMPLE_STATS).uri + '/stats_tfrecord')\n",
    "    rhs_statistics = None\n",
    "    if other_model_id:\n",
    "        rhs_statistics = tfdv.load_statistics(\n",
    "            get_input_artifact(other_model_id, TFX_ARTIFACT_EXAMPLE_STATS).uri + '/stats_tfrecord')\n",
    "    tfdv.visualize_statistics(\n",
    "        lhs_statistics,\n",
    "        rhs_statistics=rhs_statistics,\n",
    "        lhs_name='Model {}\\'s data'.format(model_id),\n",
    "        rhs_name='Model {}\\'s data'.format(other_model_id) if other_model_id else None)\n",
    "\n",
    "\n",
    "def get_input_artifact(artifact_id, input_type_name):\n",
    "    \"\"\"Returns the artifact of type `input_type_name` that directly/indirectly generated `artifact_id`.\"\"\"\n",
    "    a_events = store.get_events_by_artifact_ids([artifact_id])\n",
    "    for a_event in a_events:\n",
    "        if a_event.type != metadata_store_pb2.Event.DECLARED_OUTPUT:\n",
    "            continue\n",
    "        [execution] = store.get_executions_by_id([a_event.execution_id])\n",
    "        #print('execution_id {} -> artifact_id {}'.format(a_event.execution_id, artifact_id))\n",
    "        e_events = store.get_events_by_execution_ids([execution.id])\n",
    "        for e_event in e_events:\n",
    "            if e_event.type != metadata_store_pb2.Event.DECLARED_INPUT:\n",
    "                continue\n",
    "            [artifact] = store.get_artifacts_by_id([e_event.artifact_id])\n",
    "            [artifact_type] = store.get_artifact_types_by_id([artifact.type_id])\n",
    "            #print('artifact_id {} of type {} -> execution_id {}'.format(\n",
    "            #    artifact.id, artifact_type.name, execution.id))\n",
    "            if artifact_type.name == input_type_name:\n",
    "                return artifact\n",
    "            input_artifact = get_input_artifact(artifact.id, input_type_name)\n",
    "            if input_artifact:\n",
    "                return input_artifact\n",
    "\n",
    "\n",
    "def display_tfma_analysis(model_id, slicing_column=None):\n",
    "    \"\"\"Visualizes TFMA results for `model_id`.\"\"\"\n",
    "    model_eval_result = tfma.load_eval_result(\n",
    "        get_output_artifact(model_id, TFX_ARTIFACT_MODEL_EVAL).uri)\n",
    "    return tfma.view.render_slicing_metrics(model_eval_result, slicing_column=slicing_column)\n",
    "\n",
    "\n",
    "def compare_tfma_analysis(model_id, other_model_id):\n",
    "    \"\"\"Visualizes TFMA results for `model_id` and `other_model_id`.\"\"\"\n",
    "    model_eval_result = tfma.load_eval_result(\n",
    "        get_output_artifact(model_id, TFX_ARTIFACT_MODEL_EVAL).uri)\n",
    "    other_model_eval_result = tfma.load_eval_result(\n",
    "        get_output_artifact(other_model_id, TFX_ARTIFACT_MODEL_EVAL).uri)\n",
    "    eval_results = tfma.make_eval_results(\n",
    "        [model_eval_result, other_model_eval_result],\n",
    "        tfma.constants.MODEL_CENTRIC_MODE)\n",
    "    return tfma.view.render_time_series(eval_results, tfma.slicer.slicer.SingleSliceSpec())\n",
    "\n",
    "\n",
    "def get_output_artifact(artifact_id, output_type_name):\n",
    "    \"\"\"Returns the artifact of type `output_type_name` that was directly/indirectly generated from `artifact_id`.\"\"\"\n",
    "    a_events = store.get_events_by_artifact_ids([artifact_id])\n",
    "    for a_event in a_events:\n",
    "        if a_event.type != metadata_store_pb2.Event.DECLARED_INPUT:\n",
    "            continue\n",
    "        [execution] = store.get_executions_by_id([a_event.execution_id])\n",
    "        e_events = store.get_events_by_execution_ids([execution.id])\n",
    "        for e_event in e_events:\n",
    "            if e_event.type != metadata_store_pb2.Event.DECLARED_OUTPUT:\n",
    "                continue\n",
    "            [artifact] = store.get_artifacts_by_id([e_event.artifact_id])\n",
    "            [artifact_type] = store.get_artifact_types_by_id([artifact.type_id])\n",
    "            #print('execution_id {} -> artifact_id {} of type'.format(\n",
    "            #    execution.id, artifact.id, artifact_type.name))\n",
    "            if artifact_type.name == output_type_name:\n",
    "                return artifact\n",
    "            output_artifact = get_output_artifact(artifact.id, output_type_name)\n",
    "            if output_artifact:\n",
    "                return output_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a read-only connection to the ML-Metadata store.\n",
    "store = get_metadata_store(\n",
    "    connection_mode=metadata_store_pb2.SqliteMetadataSourceConfig.READONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize properties of the model and the trainer run that generated the model.\n",
    "model_artifact = store.get_artifacts_by_type(TFX_ARTIFACT_MODEL)[0]\n",
    "model_id = model_artifact.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize TFMA analysis for model_id.\n",
    "display_tfma_analysis(model_id, slicing_column='trip_start_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
