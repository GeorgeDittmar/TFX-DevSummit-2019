{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import networkx as nx\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow_model_analysis as tfma  # requires numpy 1.15.4.\n",
    "import tensorflow_data_validation as tfdv\n",
    "import time\n",
    "\n",
    "from ml_metadata.proto import metadata_store_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shared utils.\n",
    "%run 'mlmd_utils.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pip packages required for query workflows.\n",
    "!{sys.executable} -m pip install -q networkx\n",
    "!{sys.executable} -m pip install -q matplotlib\n",
    "!{sys.executable} -m pip install -q /google/data/rw/users/ma/martinz/ml_metadata-0.12.0.dev0-cp27-cp27mu-linux_x86_64.whl\n",
    "!{sys.executable} -m pip install -q tensorboard\n",
    "!{sys.executable} -m pip install -q papermill --user\n",
    "import papermill as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a read-only connection to the ML-Metadata store.\n",
    "store = get_metadata_store(\n",
    "    connection_mode=metadata_store_pb2.SqliteMetadataSourceConfig.READONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils to display artifacts, executions.\n",
    "def _get_value_str(p):\n",
    "    \"\"\"Returns a string representation of a metadata_store_pb2.Value object.\"\"\"\n",
    "    if p.int_value:\n",
    "        return str(p.int_value)\n",
    "    if p.string_value:\n",
    "        return p.string_value\n",
    "    if p.double_value:\n",
    "        return str(p.double_value)\n",
    "    return ''\n",
    "\n",
    "\n",
    "def get_df_from_artifacts_or_executions(objects, is_artifact):\n",
    "    \"\"\"Returns a `pd.DataFrame` of given artifact/execution objects.\"\"\"\n",
    "    data = {}\n",
    "    for o in objects:\n",
    "        col_map = {}\n",
    "        if is_artifact:\n",
    "            col_map['URI'] = o.uri\n",
    "        for p in o.properties:\n",
    "            col_map[p.upper()] = _get_value_str(o.properties[p])\n",
    "        for p in o.custom_properties:\n",
    "            col_map[p.upper()] = _get_value_str(o.custom_properties[p])\n",
    "        data[o.id] = col_map\n",
    "    df = pd.DataFrame.from_dict(data=data, orient='index').fillna('-')\n",
    "    df.index.name = 'ID'\n",
    "    return df\n",
    "\n",
    "\n",
    "def _get_df_from_single_artifact_or_execution(obj, is_artifact):\n",
    "    \"\"\"Returns a `pd.DataFrame` based on properties of an artifact/execution `obj`.\"\"\"\n",
    "    data = {}\n",
    "    if is_artifact:\n",
    "        data['URI'] = obj.uri\n",
    "    for p in obj.properties:\n",
    "        data[p.upper()] = _get_value_str(obj.properties[p])\n",
    "    for p in obj.custom_properties:\n",
    "        data[p.upper()] = _get_value_str(obj.custom_properties[p])\n",
    "    return pd.DataFrame.from_dict(data=data, orient='index', columns=['']).fillna('-')\n",
    "\n",
    "\n",
    "def get_artifact_df(artifact_id):\n",
    "    \"\"\"Returns a `pd.DataFrame` for artifact with `artifact_id`.\"\"\"\n",
    "    [artifact] = store.get_artifacts_by_id([artifact_id])\n",
    "    return _get_df_from_single_artifact_or_execution(artifact, True)\n",
    "\n",
    "\n",
    "def get_execution_df(execution_id):\n",
    "    \"\"\"Returns a `pd.DataFrame` for execution with `execution_id`.\"\"\"\n",
    "    [execution] = store.get_executions_by_id([execution_id])\n",
    "    return _get_df_from_single_artifact_or_execution(execution, False)\n",
    "\n",
    "\n",
    "def get_artifacts_of_type_df(type_name):\n",
    "    \"\"\"Returns a `pd.DataFrame` of all artifacts with `type`.\"\"\"\n",
    "    return get_df_from_artifacts_or_executions(\n",
    "        store.get_artifacts_by_type(type_name), is_artifact=True)\n",
    "\n",
    "\n",
    "def get_executions_of_type_df(type_name):\n",
    "    \"\"\"Returns a `pd.DataFrame` of all executions with `type`.\"\"\"\n",
    "    return get_df_from_artifacts_or_executions(\n",
    "        store.get_executions_by_type(type_name), is_artifact=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineage query utils.\n",
    "\n",
    "def get_input_artifact(artifact_id, input_type_name):\n",
    "    \"\"\"Returns the artifact of type `input_type_name` that directly/indirectly generated `artifact_id`.\"\"\"\n",
    "    a_events = store.get_events_by_artifact_ids([artifact_id])\n",
    "    for a_event in a_events:\n",
    "        if a_event.type != metadata_store_pb2.Event.DECLARED_OUTPUT:\n",
    "            continue\n",
    "        [execution] = store.get_executions_by_id([a_event.execution_id])\n",
    "        #print('execution_id {} -> artifact_id {}'.format(a_event.execution_id, artifact_id))\n",
    "        e_events = store.get_events_by_execution_ids([execution.id])\n",
    "        for e_event in e_events:\n",
    "            if e_event.type != metadata_store_pb2.Event.DECLARED_INPUT:\n",
    "                continue\n",
    "            [artifact] = store.get_artifacts_by_id([e_event.artifact_id])\n",
    "            [artifact_type] = store.get_artifact_types_by_id([artifact.type_id])\n",
    "            #print('artifact_id {} of type {} -> execution_id {}'.format(\n",
    "            #    artifact.id, artifact_type.name, execution.id))\n",
    "            if artifact_type.name == input_type_name:\n",
    "                return artifact\n",
    "            input_artifact = get_input_artifact(artifact.id, input_type_name)\n",
    "            if input_artifact:\n",
    "                return input_artifact\n",
    "\n",
    "\n",
    "def get_output_artifact(artifact_id, output_type_name):\n",
    "    \"\"\"Returns the artifact of type `output_type_name` that was directly/indirectly generated from `artifact_id`.\"\"\"\n",
    "    a_events = store.get_events_by_artifact_ids([artifact_id])\n",
    "    for a_event in a_events:\n",
    "        if a_event.type != metadata_store_pb2.Event.DECLARED_INPUT:\n",
    "            continue\n",
    "        [execution] = store.get_executions_by_id([a_event.execution_id])\n",
    "        e_events = store.get_events_by_execution_ids([execution.id])\n",
    "        for e_event in e_events:\n",
    "            if e_event.type != metadata_store_pb2.Event.DECLARED_OUTPUT:\n",
    "                continue\n",
    "            [artifact] = store.get_artifacts_by_id([e_event.artifact_id])\n",
    "            [artifact_type] = store.get_artifact_types_by_id([artifact.type_id])\n",
    "            #print('execution_id {} -> artifact_id {} of type'.format(\n",
    "            #    execution.id, artifact.id, artifact_type.name))\n",
    "            if artifact_type.name == output_type_name:\n",
    "                return artifact\n",
    "            output_artifact = get_output_artifact(artifact.id, output_type_name)\n",
    "            if output_artifact:\n",
    "                return output_artifact\n",
    "            \n",
    "\n",
    "def get_execution_for_output_artifact(artifact_id, execution_type_name):\n",
    "    \"\"\"\"Returns the execution of type `execution_type_name` that generated `artifact_id`.\"\"\"\n",
    "    a_events = store.get_events_by_artifact_ids([artifact_id])\n",
    "    for a_event in a_events:\n",
    "        if a_event.type != metadata_store_pb2.Event.DECLARED_OUTPUT:\n",
    "            continue\n",
    "        [execution] = store.get_executions_by_id([a_event.execution_id])\n",
    "        [execution_type] = store.get_execution_types_by_id([execution.type_id])\n",
    "        if execution_type.name == execution_type_name:\n",
    "            return execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tfma_analysis(model_id, slicing_column=None):\n",
    "    \"\"\"Visualizes TFMA results for `model_id`.\"\"\"\n",
    "    model_eval_result = tfma.load_eval_result(\n",
    "        get_output_artifact(model_id, TFX_ARTIFACT_MODEL_EVAL).uri)\n",
    "    return tfma.view.render_slicing_metrics(model_eval_result, slicing_column=slicing_column)\n",
    "\n",
    "def compare_tfma_analysis(model_id, other_model_id):\n",
    "    \"\"\"Visualizes TFMA results for `model_id` and `other_model_id`.\"\"\"\n",
    "    model_eval_result = tfma.load_eval_result(\n",
    "        get_output_artifact(model_id, TFX_ARTIFACT_MODEL_EVAL).uri)\n",
    "    other_model_eval_result = tfma.load_eval_result(\n",
    "        get_output_artifact(other_model_id, TFX_ARTIFACT_MODEL_EVAL).uri)\n",
    "    eval_results = tfma.make_eval_results(\n",
    "        [model_eval_result, other_model_eval_result],\n",
    "        tfma.constants.MODEL_CENTRIC_MODE)\n",
    "    return tfma.view.render_time_series(eval_results, tfma.slicer.slicer.SingleSliceSpec())\n",
    "\n",
    "def display_data_stats_for_model(model_id, other_model_id=None):\n",
    "    \"\"\"Visualizes stats for data that generated `model_id` and optionally `other_model_id`.\"\"\"\n",
    "    lhs_statistics = tfdv.load_statistics(\n",
    "            get_input_artifact(model_id, TFX_ARTIFACT_EXAMPLE_STATS).uri + \"/eval\")\n",
    "    rhs_statistics = None\n",
    "    if other_model_id:\n",
    "        rhs_statistics = tfdv.load_statistics(\n",
    "            get_input_artifact(other_model_id, TFX_ARTIFACT_EXAMPLE_STATS).uri)\n",
    "    tfdv.visualize_statistics(\n",
    "        lhs_statistics,\n",
    "        rhs_statistics=rhs_statistics,\n",
    "        lhs_name='Model {}\\'s data'.format(model_id),\n",
    "        rhs_name='Model {}\\'s data'.format(other_model_id) if other_model_id else None)\n",
    "    \n",
    "def display_tensorboard(model_id, other_model_id=None):\n",
    "    \"\"\"Opens up Tensorboard for `model_id` and optionally `other_model_id` and logs output to `log_filename`.\"\"\"\n",
    "    log_filename = os.path.join(\n",
    "        os.environ['HOME'],\n",
    "        'tensorboard_model_ids_{}_log.txt'.format(\n",
    "            '-'.join([str(model_id)] + [str(other_model_id)] if other_model_id else []))\n",
    "    )\n",
    "\n",
    "    [model] = store.get_artifacts_by_id([model_id])\n",
    "    logdir_arg = 'model_{}:{}'.format(model_id, model.uri)\n",
    "\n",
    "    other_model = None\n",
    "    if other_model_id:\n",
    "        [other_model] = store.get_artifacts_by_id([other_model_id])\n",
    "        logdir_arg = logdir_arg + ',model_{}:{}'.format(other_model_id, other_model.uri)\n",
    "\n",
    "    pm.execute_notebook(\n",
    "        'spawn_tensorboard.ipynb',\n",
    "        'spawn_tensorboard_output.ipynb',\n",
    "        parameters = dict(tb_logdir=logdir_arg, tb_run_log=log_filename),\n",
    "        progress_bar=False)\n",
    "    time.sleep(5)  # Give it some time for log_filename to be flushed.\n",
    "    with open(log_filename) as f:\n",
    "        for l in f.readlines():\n",
    "            if 'TensorBoard' in l:\n",
    "                return l.split(' ')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal utils used to compute lineage DAG.\n",
    "\n",
    "def _find_upstream_executions(artifact_id):\n",
    "    \"\"\"Returns a list of upstream execution ids.\"\"\"\n",
    "    result = []\n",
    "    for e in store.get_events_by_artifact_ids([artifact_id]):\n",
    "        if e.type in [metadata_store_pb2.Event.DECLARED_OUTPUT, metadata_store_pb2.Event.OUTPUT]:\n",
    "            result.append(e.execution_id)\n",
    "    return result\n",
    "\n",
    "def _find_upstream_artifacts(execution_id):\n",
    "    \"\"\"Returns a list of upstream artifact ids.\"\"\"\n",
    "    result = []\n",
    "    for e in store.get_events_by_execution_ids([execution_id]):\n",
    "        if e.type in [metadata_store_pb2.Event.DECLARED_INPUT, metadata_store_pb2.Event.INPUT]:\n",
    "            result.append(e.artifact_id)\n",
    "    return result\n",
    "\n",
    "def _add_node_attribute(g, node_id, depth, is_artifact):\n",
    "    # if it is not an artifact, use negative gnode id\n",
    "    gnode_id = node_id if is_artifact else -1 * node_id\n",
    "    g.add_node(gnode_id, depth=depth, is_artifact=is_artifact)\n",
    "    node_label = \"\" #str(node_id) + \"\\n\"\n",
    "    if is_artifact:\n",
    "        [a] = store.get_artifacts_by_id([node_id])\n",
    "        [t] = store.get_artifact_types_by_id([a.type_id])\n",
    "        node_label += t.name\n",
    "    else:\n",
    "        [e] = store.get_executions_by_id([node_id])\n",
    "        [t] = store.get_execution_types_by_id([e.type_id])\n",
    "        node_label += t.name\n",
    "    g.nodes[gnode_id]['_label_'] = node_label\n",
    "\n",
    "def _add_parents(g, node_id, is_artifact, depth, max_depth=None):\n",
    "    # if it is not an artifact, use negative gnode id\n",
    "    gnode_id = node_id if is_artifact else -1 * node_id\n",
    "    _add_node_attribute(g, node_id, depth, is_artifact)\n",
    "    if gnode_id in g and len(g.in_edges(gnode_id)) > 0: \n",
    "        return\n",
    "    if max_depth is not None and depth > max_depth:\n",
    "        return\n",
    "    if is_artifact:\n",
    "        for e_id in _find_upstream_executions(node_id):\n",
    "            g.add_edge(e_id * -1, node_id)\n",
    "            _add_parents(g, e_id, not is_artifact, depth + 1, max_depth)\n",
    "    else:\n",
    "        for a_id in _find_upstream_artifacts(node_id):\n",
    "            g.add_edge(a_id, node_id * -1)\n",
    "            _add_parents(g, a_id, not is_artifact, depth + 1, max_depth)\n",
    "\n",
    "def _construct_artifact_lineage(artifact_id, max_depth=None):\n",
    "    \"\"\"Returns a networkx DiGraph representing the lineage of the given artifact_id.\"\"\"\n",
    "    g = nx.DiGraph(query_artifact_id=artifact_id)\n",
    "    if max_depth is None or max_depth > 0:\n",
    "        _add_parents(g, artifact_id, True, 1, max_depth)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic utils to get and plot artifact lineage.\n",
    "\n",
    "def get_artifact_lineage(artifact_id, max_depth=None):\n",
    "    \"\"\"Returns lineage of artifact_id as a DAG.\n",
    "       DAG is a networkx DiGraph\n",
    "    \"\"\"\n",
    "    return _construct_artifact_lineage(artifact_id, max_depth)\n",
    "\n",
    "def plot_artifact_lineage(g):\n",
    "    \"\"\"Use networkx and matplotlib to plot the graph.\n",
    "       The nodes are places from left to right w.r.t. its depth.\n",
    "       Nodes at the same depths are placed vertically.\n",
    "       Artifact is shown in green, and Execution is shown in red.\n",
    "       Nodes are positioned in a bipartite graph layout. \n",
    "    \"\"\"\n",
    "    # make a copy of the graph; add auxilary nodes\n",
    "    dag = g.copy(as_view=False)\n",
    "    label_anchor_id = 10000\n",
    "    for node_id in g.nodes:\n",
    "        if node_id > 0:\n",
    "            dag.add_node(label_anchor_id + node_id)\n",
    "        else:\n",
    "            dag.add_node(node_id - label_anchor_id)\n",
    "\n",
    "    # assign node color and label\n",
    "    node_color = \"\"\n",
    "    node_labels = {}\n",
    "    for node_id in dag.nodes:\n",
    "        if node_id > 0 and node_id < label_anchor_id:\n",
    "            node_color += 'c' \n",
    "            node_labels[node_id] = abs(node_id)\n",
    "        elif node_id > 0 and node_id >= label_anchor_id:\n",
    "            node_color += 'w'\n",
    "            node_labels[node_id] = dag.node[node_id - label_anchor_id]['_label_']\n",
    "        elif node_id < 0 and node_id > -1 * label_anchor_id:\n",
    "            node_color += 'm'\n",
    "            node_labels[node_id] = abs(node_id)\n",
    "        else:\n",
    "            node_color += 'w'\n",
    "            node_labels[node_id] = dag.node[node_id + label_anchor_id]['_label_']                \n",
    "        \n",
    "    pos = {}\n",
    "    a_nodes = []; e_nodes = []\n",
    "    for node_id in dag.nodes:\n",
    "        if node_id > 0 and node_id < label_anchor_id:\n",
    "            a_nodes.append(node_id)\n",
    "        elif node_id < 0 and node_id > -1 * label_anchor_id:\n",
    "            e_nodes.append(node_id)\n",
    "            \n",
    "    def order_nodes_by_depth(node_id):\n",
    "        return -1 * dag.node[node_id]['depth'] + 1.0/node_id\n",
    "            \n",
    "    a_nodes.sort(key = abs)\n",
    "    e_nodes.sort(key = abs) \n",
    "    a_node_y = 0\n",
    "    e_node_y = 0.035\n",
    "    a_offset = -0.5 if len(a_nodes) % 2 == 0 else 0\n",
    "    e_offset = -0.5 if len(e_nodes) % 2 == 0 else 0\n",
    "    a_node_x_min = -1 * len(a_nodes)/2 + a_offset\n",
    "    e_node_x_min = -1 * len(e_nodes)/2 + e_offset\n",
    "    a_node_x = a_node_x_min\n",
    "    e_node_x = e_node_x_min\n",
    "    node_step = 1\n",
    "    for a_id in a_nodes:\n",
    "        pos[a_id] = [a_node_x, a_node_y]\n",
    "        pos[a_id + label_anchor_id] = [a_node_x, a_node_y - 0.01]\n",
    "        a_node_x += node_step\n",
    "    for e_id in e_nodes:\n",
    "        pos[e_id] = [e_node_x, e_node_y]\n",
    "        pos[e_id - label_anchor_id] = [e_node_x, e_node_y + 0.01]\n",
    "        e_node_x += node_step\n",
    "\n",
    "    nx.draw(dag, pos=pos,\n",
    "            node_size=500, node_color=node_color, \n",
    "            labels=node_labels, node_shape = 'o', font_size=8.3, label=\"abc\")#, ax=ax)\n",
    "    \n",
    "    legend_x = max(a_node_x, e_node_x) - 0.85\n",
    "    legend_y = 0.02\n",
    "    a_bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"c\", ec=\"b\", lw=0)\n",
    "    plt.text(legend_x - 0.0025, legend_y, \"  Artifacts  \", bbox=a_bbox_props)\n",
    "    e_bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"m\", ec=\"b\", lw=0)\n",
    "    plt.text(legend_x - 0.0025, legend_y - 0.007, \"Executions\", bbox=e_bbox_props)\n",
    "\n",
    "    x_lim_left = min(a_node_x_min, e_node_x_min) - 0.5\n",
    "    x_lim_right = min(1 - 0.05 * len(a_nodes), max(a_node_x, e_node_x))\n",
    "    \n",
    "    x_lim_left = max(-2 - 1.5/len(a_nodes), min(a_node_x_min, e_node_x_min) - 1.0)\n",
    "    x_lim_right = max(a_node_x, e_node_x) + 0.1\n",
    "    plt.xlim(x_lim_left, x_lim_right)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def get_and_plot_artifact_lineage(artifact_id, max_depth=None):\n",
    "    plot_artifact_lineage(get_artifact_lineage(artifact_id, max_depth=max_depth))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
