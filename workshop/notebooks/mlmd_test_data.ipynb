{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import six\n",
    "\n",
    "from ml_metadata.proto import metadata_store_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shared utils.\n",
    "%run 'mlmd_utils.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TFX to generate TFMA and Tensorboard events.\n",
    "# cd ~\n",
    "# git clone https://github.com/tensorflow/tfx.git\n",
    "# sudo apt-get install python-pip python-virtualenv python-dev build-essential\n",
    "# cd tfx/examples/chicago_taxi/\n",
    "# pip install -r requirements.txt\n",
    "# jupyter nbextension install --py --symlink --sys-prefix tensorflow_model_analysis\n",
    "# jupyter nbextension enable --py --sys-prefix tensorflow_model_analysis\n",
    "# \n",
    "# !! Restart your jupyter notebook to pick up these tfma notebook extensions.!!\n",
    "#\n",
    "# bash ./tfdv_analyze_and_validate_local.sh\n",
    "# bash ./preprocess_local.sh\n",
    "# bash ./train_local.sh\n",
    "# vim process_tfma.py +64\n",
    "# Change tfma.slicer.SingleSliceSpec to tfma.slicer.slicer.SingleSliceSpec. on L64 and L65.\n",
    "# bash ./process_tfma_local.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_sqlite_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util methods specific to this notebook (mlmd_test_data).\n",
    "\n",
    "def _set_artifact_or_execution_type_properties(mlmd_type, **properties):\n",
    "    \"\"\"Sets the property types in mlmd_type based on given properties.\"\"\"\n",
    "    for k, v in properties.items():\n",
    "        if isinstance(v, six.string_types):\n",
    "            mlmd_type.properties[k] = metadata_store_pb2.STRING\n",
    "        elif isinstance(v, six.integer_types):\n",
    "            mlmd_type.properties[k] = metadata_store_pb2.INT\n",
    "        elif type(v) is float:\n",
    "            mlmd_type.properties[k] = metadata_store_pb2.DOUBLE\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                '{}\\'s type {} must be a string/int/float'.format(k, type(v)))\n",
    "\n",
    "\n",
    "def create_artifact_type(store, type_name, **properties):\n",
    "    \"\"\"Creates an artifact type with given `type_name` and `properties` and returns its id.\"\"\"\n",
    "    at = metadata_store_pb2.ArtifactType()\n",
    "    at.name = type_name\n",
    "    _set_artifact_or_execution_type_properties(at, **properties)\n",
    "    return store.put_artifact_type(at)\n",
    "\n",
    "\n",
    "def create_execution_type(store, type_name, **properties):\n",
    "    \"\"\"Creates an execution type with given `type_name` and `properties` and returns its id.\"\"\"\n",
    "    et = metadata_store_pb2.ExecutionType()\n",
    "    et.name = type_name\n",
    "    _set_artifact_or_execution_type_properties(et, **properties)\n",
    "    return store.put_execution_type(et)\n",
    "\n",
    "def _set_artifact_or_execution_properties(obj, is_artifact, **properties):\n",
    "    \"\"\"Sets the properties in an artifact/execution `obj`  based on given properties.\"\"\"\n",
    "    for k, v in properties.items():\n",
    "        if is_artifact and k == 'uri':\n",
    "            obj.uri = v\n",
    "        elif isinstance(v, six.string_types):\n",
    "            obj.properties[k].string_value = v\n",
    "        elif isinstance(v, six.integer_types):\n",
    "            obj.properties[k].int_value = v\n",
    "        elif type(v) is float:\n",
    "            obj.properties[k].float_value = v\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                '{}\\'s type {} must be a string/int/float'.format(k, type(v)))\n",
    "\n",
    "def create_artifact(type_name, **properties):\n",
    "    \"\"\"Creates an artifact with given `type_name` and `properties` and returns its id.\"\"\"\n",
    "    a = metadata_store_pb2.Artifact()\n",
    "    a.type_id = tfx_artifact_types[type_name]\n",
    "    _set_artifact_or_execution_properties(a, True, **properties)\n",
    "    if random.randint(0, 10) % 2 == 0:\n",
    "        a.custom_properties['optional_tag'].int_value = random.randint(0, 100)\n",
    "    [a_id] = store.put_artifacts([a])\n",
    "    return a_id\n",
    "\n",
    "def create_execution(type_name, **properties):\n",
    "    \"\"\"Creates an execution with given `type_name` and `properties` and returns its id.\"\"\"\n",
    "    e = metadata_store_pb2.Execution()\n",
    "    e.type_id = tfx_execution_types[type_name]\n",
    "    _set_artifact_or_execution_properties(e, False, **properties)\n",
    "    if random.randint(0, 10) % 2 == 0:\n",
    "        e.custom_properties['optional_tag'].int_value = random.randint(0, 100)\n",
    "    [e_id] = store.put_executions([e])\n",
    "    return e_id\n",
    "\n",
    "def create_events(execution_id, input_artifact_ids, output_artifact_ids):\n",
    "    events = []\n",
    "\n",
    "    # Input events.\n",
    "    for input_artifact_id in input_artifact_ids:\n",
    "        e = metadata_store_pb2.Event()\n",
    "        e.artifact_id = input_artifact_id\n",
    "        e.execution_id = execution_id\n",
    "        e.type = metadata_store_pb2.Event.DECLARED_INPUT\n",
    "        events.append(e)\n",
    "\n",
    "    # Output events.\n",
    "    for output_artifact_id in output_artifact_ids:\n",
    "        e = metadata_store_pb2.Event()\n",
    "        e.artifact_id = output_artifact_id\n",
    "        e.execution_id = execution_id\n",
    "        e.type = metadata_store_pb2.Event.DECLARED_OUTPUT\n",
    "        events.append(e)\n",
    "\n",
    "    return store.put_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a `metadata_store.MetadataStore` that connects to a SQLITE backend based off\n",
    "# ~/tfx_metadata_sqlite.db.\n",
    "store = get_metadata_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TFX artifact and execution types.\n",
    "def create_tfx_artifact_types():\n",
    "    ats = {}\n",
    "    ats[TFX_ARTIFACT_EXAMPLES] = create_artifact_type(\n",
    "        store, TFX_ARTIFACT_EXAMPLES, span=0, split='', version=0)\n",
    "    ats[TFX_ARTIFACT_SCHEMA] = create_artifact_type(\n",
    "        store, TFX_ARTIFACT_SCHEMA, version=0)\n",
    "    ats[TFX_ARTIFACT_EXAMPLE_VALIDATION] = create_artifact_type(\n",
    "        store, TFX_ARTIFACT_EXAMPLE_VALIDATION)\n",
    "    ats[TFX_ARTIFACT_EXAMPLE_STATS] = create_artifact_type(\n",
    "        store, TFX_ARTIFACT_EXAMPLE_STATS, num_numeric_features=0,\n",
    "        num_categorical_features=0)\n",
    "    ats[TFX_ARTIFACT_TRANSFORMED_EXAMPLES] = create_artifact_type(\n",
    "        store, TFX_ARTIFACT_TRANSFORMED_EXAMPLES, span=0, split='', version=0,\n",
    "        transform_name=\"\")\n",
    "    ats[TFX_ARTIFACT_MODEL] = create_artifact_type(\n",
    "        store, TFX_ARTIFACT_MODEL, model_type='', model_disk_size=0)\n",
    "    ats[TFX_ARTIFACT_MODEL_EVAL] = create_artifact_type(\n",
    "        store, TFX_ARTIFACT_MODEL_EVAL, evaluation_name=\"\")\n",
    "    return ats\n",
    "\n",
    "def create_tfx_execution_types():\n",
    "    ets = {}\n",
    "    ets[TFX_EXECUTION_EXAMPLE_GEN] = create_execution_type(\n",
    "        store, TFX_EXECUTION_EXAMPLE_GEN, start_time=0, end_time=0)\n",
    "    ets[TFX_EXECUTION_STATISTICS_GEN] = create_execution_type(\n",
    "        store, TFX_EXECUTION_STATISTICS_GEN, start_time=0, end_time=0)\n",
    "    ets[TFX_EXECUTION_SCHEMA_GEN] = create_execution_type(\n",
    "        store, TFX_EXECUTION_SCHEMA_GEN, start_time=0, end_time=0)\n",
    "    ets[TFX_EXECUTION_EXAMPLE_VALIDATION] = create_execution_type(\n",
    "        store, TFX_EXECUTION_EXAMPLE_VALIDATION, start_time=0, end_time=0)\n",
    "    ets[TFX_EXECUTION_TRANSFORM] = create_execution_type(\n",
    "        store, TFX_EXECUTION_TRANSFORM, name='', start_time=0, end_time=0)\n",
    "    ets[TFX_EXECUTION_TRAINER] = create_execution_type(\n",
    "        store, TFX_EXECUTION_TRAINER, algorithm='',\n",
    "        hparams_csv='', start_time=0, end_time=0)\n",
    "    ets[TFX_EXECUTION_EVALUATOR] = create_execution_type(\n",
    "        store, TFX_EXECUTION_EVALUATOR, start_time=0, end_time=0)\n",
    "    return ets\n",
    "\n",
    "tfx_artifact_types = create_tfx_artifact_types()\n",
    "tfx_execution_types = create_tfx_execution_types()\n",
    "\n",
    "# print(tfx_artifact_types)\n",
    "# print(tfx_execution_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake some artifacts, executions and events.\n",
    "\n",
    "data_combinations = [\n",
    "    [1],  # spans\n",
    "    [\"train\", \"eval\"],  # splits\n",
    "    [1, 2] # versions\n",
    "]\n",
    "\n",
    "for span, split, version in itertools.product(*data_combinations):\n",
    "    # Simulate a run of TFX_EXECUTION_EXAMPLE_GEN.\n",
    "    # This run generates the examples.\n",
    "    example_gen_execution_id = create_execution(\n",
    "        TFX_EXECUTION_EXAMPLE_GEN, start_time=0, end_time=1) \n",
    "    examples_artifact_id = create_artifact(\n",
    "        TFX_ARTIFACT_EXAMPLES, span=span, split=split, version=version)\n",
    "    create_events(example_gen_execution_id, [], [examples_artifact_id])\n",
    "\n",
    "    # Simulate a run of TFX_EXECUTION_STATISTICS_GEN.\n",
    "    # This run consumes data to generate stats.\n",
    "    stats_gen_execution_id = create_execution(\n",
    "        TFX_EXECUTION_STATISTICS_GEN, start_time=1, end_time=2)\n",
    "    example_stats_artifact_id = create_artifact(\n",
    "        TFX_ARTIFACT_EXAMPLE_STATS, num_numeric_features=random.randrange(0, 10),\n",
    "        num_categorical_features=random.randrange(0, 10),\n",
    "        uri=os.path.join(\n",
    "            os.environ['HOME'], \n",
    "            'tfx/examples/chicago_taxi/data/local_tfdv_output/eval_stats.tfrecord'))\n",
    "    create_events(\n",
    "        stats_gen_execution_id, [examples_artifact_id],\n",
    "        [example_stats_artifact_id])\n",
    "\n",
    "    # Simulate a run of TFX_EXECUTION_SCHEMA_GEN.\n",
    "    # This run consumes stats and data to generate schema.\n",
    "    schema_gen_execution_id = create_execution(\n",
    "        TFX_EXECUTION_SCHEMA_GEN, start_time=2, end_time=3)\n",
    "    schema_artifact_id = create_artifact(TFX_ARTIFACT_SCHEMA, version=1)\n",
    "    create_events(\n",
    "        schema_gen_execution_id, [examples_artifact_id, example_stats_artifact_id],\n",
    "        [schema_artifact_id])\n",
    "\n",
    "    # Simulate a run of TFX_EXECUTION_EXAMPLE_VALIDATION.\n",
    "    # This run consumes schema and data to validate the data.\n",
    "    example_validation_execution_id = create_execution(\n",
    "        TFX_EXECUTION_EXAMPLE_VALIDATION, start_time=3, end_time=4)\n",
    "    example_validation_artifact_id = create_artifact(TFX_ARTIFACT_EXAMPLE_VALIDATION)\n",
    "    create_events(\n",
    "        example_validation_execution_id, [examples_artifact_id, schema_artifact_id],\n",
    "        [example_validation_artifact_id])\n",
    "    \n",
    "    # Simulate a run of TFX_EXECUTION_TRANSFORM.\n",
    "    # This run consumes data and schema to generate transformed data.\n",
    "    transform_execution_id = create_execution(\n",
    "        TFX_EXECUTION_TRANSFORM, name='transform', start_time=4, end_time=5)\n",
    "    transformed_examples_artifact_id = create_artifact(\n",
    "        TFX_ARTIFACT_TRANSFORMED_EXAMPLES, span=span, split=split, version=version,\n",
    "        transform_name='transform')\n",
    "    create_events(\n",
    "        transform_execution_id, [examples_artifact_id, schema_artifact_id],\n",
    "        [transformed_examples_artifact_id])\n",
    "\n",
    "    # Simulate a run of TFX_EXECUTION_TRAINER.\n",
    "    # This run consumes transformed data to generate a model and checkpoints/events along the way.\n",
    "    trainer_execution_id = create_execution(\n",
    "        TFX_EXECUTION_TRAINER, algorithm='DNNLinearCombined',\n",
    "        hparams_csv=\"dnn_hidden_units=[10, 10],dropout=0.1,activation=relu\",\n",
    "        start_time=5, end_time=6)\n",
    "    model_artifact_id = create_artifact(\n",
    "        TFX_ARTIFACT_MODEL, model_type=\"tensorflow\",\n",
    "        model_disk_size=random.randrange(0, 100*1000*1000),\n",
    "        uri=os.path.join(\n",
    "            os.environ['HOME'], \n",
    "            'tfx/examples/chicago_taxi/data/train/local_chicago_taxi_output/serving_model_dir'))\n",
    "    create_events(\n",
    "        trainer_execution_id, [transformed_examples_artifact_id],\n",
    "        [model_artifact_id])\n",
    "\n",
    "    # Simulate a run of TFX_EXECUTION_EVALUATOR.\n",
    "    # This run consumes data and model to generate an eval result.\n",
    "    evaluator_execution_id = create_execution(\n",
    "        TFX_EXECUTION_EVALUATOR,\n",
    "        start_time=6, end_time=7)\n",
    "    model_eval_artifact_id = create_artifact(\n",
    "        TFX_ARTIFACT_MODEL_EVAL,\n",
    "        uri=os.path.join(\n",
    "            os.environ['HOME'], \n",
    "            'tfx/examples/chicago_taxi/data/train/local_chicago_taxi_output/eval_result'),\n",
    "        evaluation_name='tfma_eval_run')\n",
    "    create_events(\n",
    "        evaluator_execution_id, [examples_artifact_id, model_artifact_id],\n",
    "        [model_eval_artifact_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[artifact_id: 5\n",
      "execution_id: 5\n",
      "type: DECLARED_OUTPUT\n",
      "milliseconds_since_epoch: 1550115700689\n",
      ", artifact_id: 5\n",
      "execution_id: 6\n",
      "type: DECLARED_INPUT\n",
      "milliseconds_since_epoch: 1550115700706\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# test read only mode.\n",
    "r_store = get_metadata_store(\n",
    "    connection_mode=metadata_store_pb2.SqliteMetadataSourceConfig.READONLY)\n",
    "#print(r_store.get_artifacts_by_type(TFX_ARTIFACT_MODEL))\n",
    "#print(r_store.get_events_by_execution_ids([6]))\n",
    "print(r_store.get_events_by_artifact_ids([5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
